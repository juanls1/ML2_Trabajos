{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humanoid Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# To get smooth animations\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el entorno Humanoid\n",
    "env = gym.make(\"Humanoid-v4\", render_mode='human')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.40089773e+00,  9.99897788e-01, -7.66129031e-03,  7.48330749e-03,\n",
       "        -9.47194206e-03,  6.09659749e-03, -3.90875665e-03,  8.27559572e-03,\n",
       "        -1.89389489e-03,  5.85556405e-03,  1.24976935e-03,  6.33932036e-03,\n",
       "        -5.42981506e-03, -5.12888324e-03,  9.03139958e-03, -4.62746199e-03,\n",
       "         2.75643350e-03, -6.60397168e-03, -6.57194243e-03,  4.57250598e-03,\n",
       "         1.77490595e-03,  5.17077391e-03,  9.05367625e-03,  5.48874419e-03,\n",
       "         8.39544396e-04,  2.02187204e-03,  3.54659908e-03,  1.75778583e-03,\n",
       "        -4.38448080e-03,  4.99472649e-03,  9.35861584e-03,  8.59264612e-03,\n",
       "         4.31193807e-03, -9.23030681e-03, -9.25550563e-03,  1.73147902e-03,\n",
       "         7.40642682e-03, -8.34437842e-03,  3.38145327e-03, -8.12498102e-03,\n",
       "        -7.08681191e-03,  6.72073070e-03, -5.24704762e-03,  5.52260102e-03,\n",
       "         5.28915642e-04,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.30524075e+00,\n",
       "         2.28695525e+00,  4.26174204e-02,  6.31489620e-05,  4.03838072e-02,\n",
       "        -2.51452623e-02, -9.37535483e-02,  4.80474437e-02,  4.35780795e+00,\n",
       "         8.90746237e+00,  9.56398097e-02,  9.06464198e-02,  1.09671157e-02,\n",
       "        -2.45451423e-05,  9.77244682e-03, -3.73013634e-04, -5.01747325e-02,\n",
       "         2.39814490e-03,  4.40501521e-01,  2.26194671e+00,  5.81972753e-02,\n",
       "         4.26490884e-02,  6.47556038e-02, -4.66768548e-04,  8.55659523e-03,\n",
       "         2.74753121e-04, -2.86867110e-01, -2.52866081e-03,  1.97287400e-01,\n",
       "         6.61619413e+00,  2.73274404e-01,  2.31218573e-01,  5.64499655e-02,\n",
       "        -1.17859168e-02, -2.20088601e-02, -8.17730562e-02, -1.21019883e-01,\n",
       "        -4.62987876e-01, -8.53245594e-01,  4.75175093e+00,  9.30143193e-01,\n",
       "         9.06676427e-01,  3.03914025e-02, -6.87704596e-03, -4.02984120e-02,\n",
       "        -1.48907080e-01, -7.17328234e-02, -2.64209402e-01, -1.55033156e+00,\n",
       "         2.75569617e+00,  1.04849067e+00,  1.03279121e+00,  2.19985220e-02,\n",
       "        -4.42536522e-03, -3.45486796e-02, -1.31632893e-01, -4.53048056e-02,\n",
       "        -1.72614489e-01, -1.34759559e+00,  1.76714587e+00,  2.72302715e-01,\n",
       "         2.33246589e-01,  5.29137904e-02,  1.08038152e-02, -2.17075468e-02,\n",
       "         7.85768071e-02, -1.15450981e-01,  4.45709980e-01, -8.59740370e-01,\n",
       "         4.75175093e+00,  9.30249479e-01,  9.11258395e-01,  2.70720290e-02,\n",
       "         7.22752209e-03, -4.67036471e-02,  1.37005456e-01, -8.19546156e-02,\n",
       "         2.43048540e-01, -1.55389096e+00,  2.75569617e+00,  1.04871130e+00,\n",
       "         1.03699451e+00,  1.95597714e-02,  5.13732313e-03, -4.46492279e-02,\n",
       "         1.18636244e-01, -5.84524775e-02,  1.55312482e-01, -1.34984353e+00,\n",
       "         1.76714587e+00,  4.29442679e-01,  3.34479911e-01,  1.19499848e-01,\n",
       "         3.17817556e-02, -4.29518668e-02,  1.74072058e-01,  1.09127472e-01,\n",
       "        -4.10338830e-01,  7.25219062e-01,  1.66108048e+00,  3.20603250e-01,\n",
       "         3.42933455e-01,  1.76095492e-01,  7.80047815e-02, -1.54478269e-01,\n",
       "         1.27493569e-01,  3.40129896e-01, -2.98265182e-01,  5.42534587e-01,\n",
       "         1.22954019e+00,  4.24642566e-01,  3.27710771e-01,  1.27015529e-01,\n",
       "        -3.66103300e-02, -4.90339850e-02, -1.76116944e-01,  1.25718491e-01,\n",
       "         4.21040095e-01,  7.13990822e-01,  1.66108048e+00,  3.15161892e-01,\n",
       "         3.43532559e-01,  1.79754141e-01, -7.96778727e-02, -1.57147930e-01,\n",
       "        -1.24696853e-01,  3.49735119e-01,  2.95387754e-01,  5.37306263e-01,\n",
       "         1.22954019e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.11461615e-03,\n",
       "         3.53369820e-03,  1.67257829e-03,  7.45553411e-03,  6.46415372e-03,\n",
       "         7.99279783e-04,  2.12949097e-03,  8.46054094e-03, -2.78802300e-03,\n",
       "         6.16669307e-03,  6.37116016e-03,  6.92268211e-04,  1.14873002e-02,\n",
       "         8.34094171e-03, -2.81616653e-03,  6.18220978e-03,  7.58474084e-03,\n",
       "         6.94365572e-04,  2.00290087e-02, -9.59877535e-04,  1.55278706e-03,\n",
       "         5.65271929e-03,  7.61153024e-03,  1.78659892e-03,  2.00928418e-02,\n",
       "         8.29503331e-03,  1.46950999e-03,  9.29404346e-03,  7.58427382e-03,\n",
       "         1.54861378e-03,  2.00928418e-02,  8.29503331e-03,  1.46950999e-03,\n",
       "         9.29404346e-03,  7.58427382e-03,  1.54861378e-03,  9.66973862e-03,\n",
       "         6.70207841e-06, -1.02033543e-02,  5.35909553e-03,  7.44059122e-03,\n",
       "         1.05951647e-03,  9.64388419e-03, -3.37464760e-03, -1.01976859e-02,\n",
       "         4.02765919e-03,  7.45092797e-03,  1.15277343e-03,  9.64388419e-03,\n",
       "        -3.37464760e-03, -1.01976859e-02,  4.02765919e-03,  7.45092797e-03,\n",
       "         1.15277343e-03, -4.62230618e-03,  5.23896760e-03, -6.57024607e-03,\n",
       "         7.92727814e-03,  2.89106996e-03, -3.25477083e-04, -4.62964118e-03,\n",
       "         5.49199149e-04, -1.75628313e-03,  7.81503588e-03,  2.11200295e-03,\n",
       "        -1.08461612e-03, -2.04247172e-03,  9.67335569e-03,  3.42010712e-03,\n",
       "         4.61967091e-03,  4.34384991e-03,  1.50256241e-03, -2.05376313e-03,\n",
       "         9.29514187e-03,  3.05054174e-03,  4.61383218e-03,  4.40512232e-03,\n",
       "         1.44003452e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]),\n",
       " {})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar la tabla Q con valores iniciales\n",
    "\n",
    "env.reset() # reset the environment to a new random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space Box(-0.4, 0.4, (17,), float32)\n",
      "State Space Box(-inf, inf, (376,), float64).\n"
     ]
    }
   ],
   "source": [
    "print(\"Action Space {}\". format(env.action_space))\n",
    "print(\"State Space {}.\". format(env.observation_space))\n",
    "\n",
    "action_space_size = env.action_space.shape[0]\n",
    "state_space_size = env.observation_space.shape[0]\n",
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 17)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir parámetros\n",
    "alpha = 0.1  # Tasa de aprendizaje\n",
    "gamma = 0.99  # Factor de descuento\n",
    "epsilon = 0.1  # Probabilidad de exploración inicial\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para elegir una acción basada en la política epsilon-greedy\n",
    "def choose_action(state):\n",
    "    state_index = hash(tuple(state))\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        return env.action_space.sample()  # Exploración aleatoria\n",
    "    else:\n",
    "        return np.argmax(q_table[state_index, :])  # Explotación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m state[np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not NoneType"
     ]
    }
   ],
   "source": [
    "state[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1485138634596624568 is out of bounds for axis 0 with size 376",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Elegir una acción\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     action \u001b[38;5;241m=\u001b[39m choose_action(state2)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Tomar la acción y observar el siguiente estado y la recompensa\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     next_state, reward, done, truncate, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action) \n",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m, in \u001b[0;36mchoose_action\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# Exploración aleatoria\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmax(q_table[state_index, :])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1485138634596624568 is out of bounds for axis 0 with size 376"
     ]
    }
   ],
   "source": [
    "# Bucle de entrenamiento\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    state2 = state[0]\n",
    "\n",
    "    epochs, penalties, reward, = 0, 0, 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Elegir una acción\n",
    "        action = np.random.randn(env.action_space.shape[0],1)\n",
    "        action = choose_action(state2)\n",
    "        # Tomar la acción y observar el siguiente estado y la recompensa\n",
    "        next_state, reward, done, truncate, info = env.step(action) \n",
    "  \n",
    "        old_value = q_table[state, action]\n",
    "        next_max = np.max(q_table[next_state])\n",
    "  \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        #print(state[0], action, new_value)\n",
    "        q_table[state,action] = new_value\n",
    "        #print(state[0], action, new_value)\n",
    "        #print(reward)\n",
    "        \n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        state= next_state\n",
    "        epochs += 1\n",
    "        #print(state)\n",
    "    if episode % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Episode: {episode}\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
